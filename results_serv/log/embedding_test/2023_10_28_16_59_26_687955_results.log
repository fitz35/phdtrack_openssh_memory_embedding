2023_10_28_16_59_26 - results_logger - INFO - Passed program params:
2023_10_28_16_59_26 - results_logger - INFO - param[0]: main.py
2023_10_28_16_59_26 - results_logger - INFO - param[1]: -d
2023_10_28_16_59_26 - results_logger - INFO - param[2]: /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none
2023_10_28_16_59_26 - results_logger - INFO - param[3]: -p
2023_10_28_16_59_26 - results_logger - INFO - param[4]: deeplearning
2023_10_28_16_59_26 - results_logger - INFO - param[5]: -o
2023_10_28_16_59_26 - results_logger - INFO - param[6]: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/output/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none
2023_10_28_16_59_26 - results_logger - INFO - param[7]: -otr
2023_10_28_16_59_26 - results_logger - INFO - param[8]: training
2023_10_28_16_59_26 - results_logger - INFO - param[9]: -ots
2023_10_28_16_59_26 - results_logger - INFO - param[10]: validation
2023_10_28_16_59_26 - results_logger - INFO - ///---!!!! Launching embedding pipeline on dataset /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none !!!!----///
2023_10_28_16_59_26 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_28_16_59_26 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_28_16_59_26 - results_logger - INFO - Pipeline start time : 1698512366.6956801 seconds
2023_10_28_16_59_26 - results_logger - INFO - timer for load_samples_and_labels_from_all_csv_files started
2023_10_28_16_59_26 - results_logger - INFO - Loading samples and labels from 3735 files
2023_10_28_16_59_47 - results_logger - INFO - Number of loaded files: 3735
2023_10_28_16_59_47 - results_logger - INFO - Number of empty files: 0
2023_10_28_16_59_47 - results_logger - INFO - Loading samples and labels from 20964 files
2023_10_28_17_01_38 - results_logger - INFO - Number of loaded files: 20964
2023_10_28_17_01_38 - results_logger - INFO - Number of empty files: 0
2023_10_28_17_01_39 - results_logger - INFO - Time elapsed since the begining of load_samples_and_labels_from_all_csv_files: 133.092945000 s
2023_10_28_17_01_39 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_28_17_01_39 - results_logger - INFO - Transformers instance TransformersHyperParams(index=0, word_character_size=16, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu') already computed
2023_10_28_17_01_39 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim16_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_28_17_01_39 - results_logger - INFO - Transformers instance TransformersHyperParams(index=1, word_character_size=16, embedding_dim=16, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu') already computed
2023_10_28_17_01_39 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_28_17_01_39 - results_logger - INFO - Transformers instance TransformersHyperParams(index=2, word_character_size=8, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu') already computed
2023_10_28_17_01_39 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim16_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_28_17_01_39 - results_logger - INFO - Transformers instance TransformersHyperParams(index=3, word_character_size=8, embedding_dim=16, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu') already computed
2023_10_28_17_01_39 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim8_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_28_17_01_39 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=4, word_character_size=16, embedding_dim=8, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_28_17_02_02 - results_logger - INFO - token number for instance 4 (with padding) : 2049
2023_10_28_17_02_04 - results_logger - INFO - encoder summary : Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense (Dense)               (None, None, 8)           16        
                                                                 
 model (Functional)          (None, 2049, 8)           676       
                                                                 
 model_1 (Functional)        (None, 2049, 8)           676       
                                                                 
 model_2 (Functional)        (None, 2049, 8)           676       
                                                                 
 model_3 (Functional)        (None, 2049, 8)           676       
                                                                 
 global_average_pooling1d (  (None, 8)                 0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_9 (Dense)             (None, 8)                 72        
                                                                 
=================================================================
Total params: 2792 (10.91 KB)
Trainable params: 2792 (10.91 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_28_17_02_04 - results_logger - INFO - timer for transformers training :  started
2023_10_28_19_32_05 - results_logger - ERROR - Timeout error in transformers pipeline 4, skipping
2023_10_28_19_32_05 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim16_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_28_19_32_05 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=5, word_character_size=16, embedding_dim=16, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_28_19_32_24 - results_logger - INFO - token number for instance 5 (with padding) : 2049
2023_10_28_19_32_25 - results_logger - INFO - encoder summary : Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense_10 (Dense)            (None, None, 16)          32        
                                                                 
 model_5 (Functional)        (None, 2049, 16)          1300      
                                                                 
 model_6 (Functional)        (None, 2049, 16)          1300      
                                                                 
 model_7 (Functional)        (None, 2049, 16)          1300      
                                                                 
 model_8 (Functional)        (None, 2049, 16)          1300      
                                                                 
 global_average_pooling1d_1  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_19 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 5504 (21.50 KB)
Trainable params: 5504 (21.50 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_28_19_32_25 - results_logger - INFO - timer for transformers training :  started
2023_10_28_22_02_25 - results_logger - ERROR - Timeout error in transformers pipeline 5, skipping
2023_10_28_22_02_25 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim8_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_28_22_02_25 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=6, word_character_size=8, embedding_dim=8, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_28_22_03_00 - results_logger - INFO - token number for instance 6 (with padding) : 4098
2023_10_28_22_03_00 - results_logger - INFO - encoder summary : Model: "model_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_20 (Dense)            (None, None, 8)           16        
                                                                 
 model_10 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_11 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_12 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_13 (Functional)       (None, 4098, 8)           676       
                                                                 
 global_average_pooling1d_2  (None, 8)                 0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_29 (Dense)            (None, 8)                 72        
                                                                 
=================================================================
Total params: 2792 (10.91 KB)
Trainable params: 2792 (10.91 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_28_22_03_00 - results_logger - INFO - timer for transformers training :  started
2023_10_29_00_33_04 - results_logger - ERROR - Timeout error in transformers pipeline 6, skipping
2023_10_29_00_33_04 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim16_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_29_00_33_04 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=7, word_character_size=8, embedding_dim=16, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_29_00_33_35 - results_logger - INFO - token number for instance 7 (with padding) : 4098
2023_10_29_00_33_36 - results_logger - INFO - encoder summary : Model: "model_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_30 (Dense)            (None, None, 16)          32        
                                                                 
 model_15 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_16 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_17 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_18 (Functional)       (None, 4098, 16)          1300      
                                                                 
 global_average_pooling1d_3  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_39 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 5504 (21.50 KB)
Trainable params: 5504 (21.50 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_00_33_36 - results_logger - INFO - timer for transformers training :  started
2023_10_29_03_03_39 - results_logger - ERROR - Timeout error in transformers pipeline 7, skipping
2023_10_29_03_03_39 - results_logger - INFO - !!!!!!!!!!!!! Word2vec instance : word2vec_output_size8_word_character_size2_word_character_size2_min_count1 !!!!!!!!!!!!!
2023_10_29_03_03_39 - results_logger - INFO - Word2Vec instance : Word2vecHyperparams(index=0, output_size=8, window_character_size=8, word_character_size=2, min_count=1)
2023_10_29_03_04_17 - results_logger - INFO - max_length_train : 16392
2023_10_29_03_04_17 - results_logger - INFO - timer for word2vec training :  started
2023_10_29_03_13_51 - results_logger - INFO - Time elapsed since the begining of word2vec training : : 574.726509000 s
2023_10_29_03_13_51 - results_logger - INFO - timer for word2vec used to embedde :  started
2023_10_29_03_17_56 - results_logger - INFO - Time elapsed since the begining of word2vec used to embedde : : 244.071507000 s
2023_10_29_03_17_56 - results_logger - INFO - ///---!!!! Launching testing pipeline on dataset /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none !!!!----///
2023_10_29_03_17_56 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_29_03_17_56 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_29_03_17_56 - results_logger - INFO - Start time : 1698549476.0094516
2023_10_29_03_17_56 - results_logger - INFO - Using already loaded data
2023_10_29_03_17_56 - results_logger - INFO - timer for feature_engineering started
2023_10_29_03_17_56 - results_logger - INFO - Computing correlation (algorithm: pearson)...
2023_10_29_03_17_56 - results_logger - INFO - Correlation matrix (algorithm: pearson): 
           feature_0  feature_1  feature_2  ...  feature_5  feature_6  feature_7
feature_0   1.000000   0.717789   0.609532  ...  -0.384756  -0.136658  -0.475969
feature_1   0.717789   1.000000   0.369624  ...  -0.735209  -0.262077  -0.490865
feature_2   0.609532   0.369624   1.000000  ...   0.056880  -0.323983  -0.615342
feature_3  -0.594405  -0.156776  -0.335983  ...   0.113185   0.255155   0.255566
feature_4  -0.608862  -0.167153  -0.418307  ...  -0.024585   0.544772   0.385415
feature_5  -0.384756  -0.735209   0.056880  ...   1.000000   0.100228   0.055197
feature_6  -0.136658  -0.262077  -0.323983  ...   0.100228   1.000000   0.380157
feature_7  -0.475969  -0.490865  -0.615342  ...   0.055197   0.380157   1.000000

[8 rows x 8 columns]
2023_10_29_03_17_56 - results_logger - INFO - Correlation matrix saved at: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_03_17_56_265570.png and /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_03_17_56_265530.csv
2023_10_29_03_17_56 - results_logger - INFO - Correlation sums: 
feature_0    4.527970
feature_1    3.899492
feature_2    3.729651
feature_3    3.276643
feature_4    3.714666
feature_5    2.470039
feature_6    3.003031
feature_7    3.658510
dtype: float64
2023_10_29_03_17_56 - results_logger - INFO - Sorted correlation sums: 
feature_0    4.527970
feature_1    3.899492
feature_2    3.729651
feature_4    3.714666
feature_7    3.658510
feature_3    3.276643
feature_6    3.003031
feature_5    2.470039
dtype: float64
2023_10_29_03_17_56 - results_logger - INFO - Keeping columns: ['feature_5', 'feature_6', 'feature_3', 'feature_7', 'feature_4', 'feature_2', 'feature_1', 'feature_0']
2023_10_29_03_17_56 - results_logger - INFO - End feature engineering
2023_10_29_03_17_56 - results_logger - INFO - Time elapsed since the begining of feature_engineering: 0.473327000 s
2023_10_29_03_17_56 - results_logger - INFO - Keeping 8 : ['feature_5', 'feature_6', 'feature_3', 'feature_7', 'feature_4', 'feature_2', 'feature_1', 'feature_0']
2023_10_29_03_17_56 - results_logger - INFO - Keeping 8 : ['feature_5', 'feature_6', 'feature_3', 'feature_7', 'feature_4', 'feature_2', 'feature_1', 'feature_0']
2023_10_29_03_17_56 - results_logger - INFO - Number of samples before balancing: class-0.0=620669 class-1.0=125784 class-2.0=20964 class-4.0=20964
2023_10_29_03_17_56 - results_logger - INFO - timer for resample_data (RandomUnderSampler) started
2023_10_29_03_17_56 - results_logger - INFO - Time elapsed since the begining of resample_data (RandomUnderSampler): 0.155697000 s
2023_10_29_03_17_56 - results_logger - INFO - Number of samples after balancing: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_03_17_56 - results_logger - INFO - timer for random forest :  started
2023_10_29_03_17_57 - results_logger - INFO - timer for evaluate_model_score started
2023_10_29_03_17_58 - results_logger - INFO - Sample of predicted labels: [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
 versus actual labels: 0     0.0
1     1.0
2     0.0
3     0.0
4     0.0
5     0.0
6     0.0
7     0.0
8     0.0
9     0.0
10    0.0
11    0.0
12    0.0
13    0.0
14    1.0
15    0.0
16    0.0
17    0.0
18    0.0
19    0.0
Name: label, dtype: float64
2023_10_29_03_17_58 - results_logger - INFO - Number of predicted 1 labels: 50377.0 
 versus number of predicted 0 labels: 89701.0
2023_10_29_03_17_58 - results_logger - INFO - Accuracy: 96.38%
2023_10_29_03_17_58 - results_logger - INFO - {
    "0.0": {
        "precision": 0.998561042108452,
        "recall": 0.9571861558285994,
        "f1-score": 0.9774359449566788,
        "support": 110198.0
    },
    "1.0": {
        "precision": 0.8329512570934646,
        "recall": 0.9890227576974565,
        "f1-score": 0.9043024133499256,
        "support": 22410.0
    },
    "2.0": {
        "precision": 0.9659630606860158,
        "recall": 0.9801874163319947,
        "f1-score": 0.9730232558139535,
        "support": 3735.0
    },
    "4.0": {
        "precision": 0.9157400543612553,
        "recall": 0.992235609103079,
        "f1-score": 0.9524543819069649,
        "support": 3735.0
    },
    "accuracy": 0.9638272962206771,
    "macro avg": {
        "precision": 0.9283038535622969,
        "recall": 0.9796579847402824,
        "f1-score": 0.9518039990068807,
        "support": 140078.0
    },
    "weighted avg": {
        "precision": 0.9689889099247081,
        "recall": 0.9638272962206771,
        "f1-score": 0.9649521146960662,
        "support": 140078.0
    }
}
2023_10_29_03_17_58 - results_logger - INFO - Confusion Matrix: 
2023_10_29_03_17_58 - results_logger - INFO - True Positives: 22164
2023_10_29_03_17_58 - results_logger - INFO - True Negatives: 105480
2023_10_29_03_17_58 - results_logger - INFO - False Positives: 4437
2023_10_29_03_17_58 - results_logger - INFO - False Negatives: 152
2023_10_29_03_17_58 - results_logger - INFO - AUC: 0.91
2023_10_29_03_17_58 - results_logger - INFO - Time elapsed since the begining of evaluate_model_score: 0.733058000 s
2023_10_29_03_17_58 - results_logger - INFO - Time elapsed since the begining of random forest : : 1.861803000 s
2023_10_29_03_17_58 - results_logger - INFO - timer for clustering started
2023_10_29_03_17_58 - results_logger - INFO - timer for scaling_duration started
2023_10_29_03_17_58 - results_logger - INFO - Time elapsed since the begining of scaling_duration: 0.001046000 s
2023_10_29_03_17_58 - results_logger - INFO - Number of samples before rebalancing and limiting rows: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_03_17_58 - results_logger - INFO - Number of samples after rebalancing and limiting rows: class-0.0=1875 class-1.0=1875 class-2.0=1875 class-4.0=1875
2023_10_29_03_17_58 - results_logger - INFO - min_samples: 937
2023_10_29_03_17_58 - results_logger - INFO - timer for clustering_duration_for_0.01 started
2023_10_29_03_33_03 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.01: 905.346054000 s
2023_10_29_03_33_03 - results_logger - WARNING - WARN: n_clusters <= 1 !!! eps: 0.01, number of clusters: 1
2023_10_29_03_33_03 - results_logger - INFO - timer for clustering_duration_for_0.02 started
2023_10_29_03_48_52 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.02: 948.457624000 s
2023_10_29_03_48_52 - results_logger - WARNING - WARN: n_clusters <= 1 !!! eps: 0.02, number of clusters: 1
2023_10_29_03_48_52 - results_logger - INFO - timer for clustering_duration_for_0.03 started
2023_10_29_04_02_06 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.03: 794.610969000 s
2023_10_29_04_02_06 - results_logger - WARNING - WARN: n_clusters <= 1 !!! eps: 0.03, number of clusters: 1
2023_10_29_04_02_06 - results_logger - INFO - timer for clustering_duration_for_0.04 started
2023_10_29_04_15_57 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.04: 830.862143000 s
2023_10_29_04_15_57 - results_logger - WARNING - WARN: n_clusters <= 1 !!! eps: 0.04, number of clusters: 1
2023_10_29_04_15_57 - results_logger - INFO - timer for clustering_duration_for_0.05 started
