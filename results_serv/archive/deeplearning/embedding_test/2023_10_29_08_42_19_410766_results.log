2023_10_29_08_42_19 - results_logger - INFO - Passed program params:
2023_10_29_08_42_19 - results_logger - INFO - param[0]: main.py
2023_10_29_08_42_19 - results_logger - INFO - param[1]: -d
2023_10_29_08_42_19 - results_logger - INFO - param[2]: /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none
2023_10_29_08_42_19 - results_logger - INFO - param[3]: -p
2023_10_29_08_42_19 - results_logger - INFO - param[4]: deeplearning
2023_10_29_08_42_19 - results_logger - INFO - param[5]: -o
2023_10_29_08_42_19 - results_logger - INFO - param[6]: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/output/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none
2023_10_29_08_42_19 - results_logger - INFO - param[7]: -otr
2023_10_29_08_42_19 - results_logger - INFO - param[8]: training
2023_10_29_08_42_19 - results_logger - INFO - param[9]: -ots
2023_10_29_08_42_19 - results_logger - INFO - param[10]: validation
2023_10_29_08_42_19 - results_logger - INFO - ///---!!!! Launching embedding pipeline on dataset /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none !!!!----///
2023_10_29_08_42_19 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_29_08_42_19 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_29_08_42_19 - results_logger - INFO - Pipeline start time : 1698568939.4185615 seconds
2023_10_29_08_42_19 - results_logger - INFO - timer for load_samples_and_labels_from_all_csv_files started
2023_10_29_08_42_19 - results_logger - INFO - Loading samples and labels from 20964 files
2023_10_29_08_44_13 - results_logger - INFO - Number of loaded files: 20964
2023_10_29_08_44_13 - results_logger - INFO - Number of empty files: 0
2023_10_29_08_44_15 - results_logger - INFO - Loading samples and labels from 3735 files
2023_10_29_08_44_35 - results_logger - INFO - Number of loaded files: 3735
2023_10_29_08_44_35 - results_logger - INFO - Number of empty files: 0
2023_10_29_08_44_35 - results_logger - INFO - Time elapsed since the begining of load_samples_and_labels_from_all_csv_files: 136.214647000 s
2023_10_29_08_44_35 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_29_08_44_35 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=0, word_character_size=16, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_29_08_44_59 - results_logger - INFO - token number for instance 0 (with padding) : 2049
2023_10_29_08_45_00 - results_logger - INFO - encoder summary : Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense (Dense)               (None, None, 8)           16        
                                                                 
 model (Functional)          (None, 2049, 8)           222       
                                                                 
 model_1 (Functional)        (None, 2049, 8)           222       
                                                                 
 global_average_pooling1d (  (None, 8)                 0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_5 (Dense)             (None, 8)                 72        
                                                                 
=================================================================
Total params: 532 (2.08 KB)
Trainable params: 532 (2.08 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_08_45_00 - results_logger - INFO - timer for transformers training :  started
2023_10_29_10_07_27 - results_logger - INFO - Time elapsed since the begining of transformers training : : 4947.369620000 s
2023_10_29_10_07_27 - results_logger - INFO - TransformersHyperParams : {'index': 0, 'word_character_size': 16, 'embedding_dim': 8, 'transformer_units': 2, 'num_heads': 2, 'num_transformer_layers': 2, 'dropout_rate': 0.1, 'activation': 'relu'}
2023_10_29_10_07_27 - results_logger - INFO - ///---!!!! Launching testing pipeline on dataset /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none !!!!----///
2023_10_29_10_07_27 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_29_10_07_27 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_29_10_07_27 - results_logger - INFO - Start time : 1698574047.6117747
2023_10_29_10_07_27 - results_logger - INFO - Using already loaded data
2023_10_29_10_07_27 - results_logger - INFO - timer for feature_engineering started
2023_10_29_10_07_27 - results_logger - INFO - Computing correlation (algorithm: pearson)...
2023_10_29_10_07_28 - results_logger - INFO - Correlation matrix (algorithm: pearson): 
            embedded_0  embedded_1  ...  embedded_6  embedded_7
embedded_0    1.000000   -0.898938  ...         NaN   -0.926806
embedded_1   -0.898938    1.000000  ...         NaN    0.963944
embedded_2   -0.908254    0.958782  ...         NaN    0.992756
embedded_3   -0.547591    0.758727  ...         NaN    0.657704
embedded_4   -0.795346    0.904002  ...         NaN    0.953678
embedded_5    0.785327   -0.869871  ...         NaN   -0.936627
embedded_6         NaN         NaN  ...         NaN         NaN
embedded_7   -0.926806    0.963944  ...         NaN    1.000000

[8 rows x 8 columns]
2023_10_29_10_07_28 - results_logger - INFO - Correlation matrix saved at: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_10_07_28_022578.png and /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_10_07_28_022508.csv
2023_10_29_10_07_28 - results_logger - INFO - Correlation sums: 
embedded_0    5.862261
embedded_1    6.354263
embedded_2    6.398629
embedded_3    4.575845
embedded_4    6.169437
embedded_5    6.016708
embedded_6    0.000000
embedded_7    6.431515
dtype: float64
2023_10_29_10_07_28 - results_logger - INFO - Sorted correlation sums: 
embedded_7    6.431515
embedded_2    6.398629
embedded_1    6.354263
embedded_4    6.169437
embedded_5    6.016708
embedded_0    5.862261
embedded_3    4.575845
embedded_6    0.000000
dtype: float64
2023_10_29_10_07_28 - results_logger - INFO - Keeping columns: ['embedded_6', 'embedded_3', 'embedded_0', 'embedded_5', 'embedded_4', 'embedded_1', 'embedded_2', 'embedded_7']
2023_10_29_10_07_28 - results_logger - INFO - End feature engineering
2023_10_29_10_07_28 - results_logger - INFO - Time elapsed since the begining of feature_engineering: 0.640231000 s
2023_10_29_10_07_28 - results_logger - INFO - Keeping 8 : ['embedded_6', 'embedded_3', 'embedded_0', 'embedded_5', 'embedded_4', 'embedded_1', 'embedded_2', 'embedded_7']
2023_10_29_10_07_28 - results_logger - INFO - Keeping 8 : ['embedded_6', 'embedded_3', 'embedded_0', 'embedded_5', 'embedded_4', 'embedded_1', 'embedded_2', 'embedded_7']
2023_10_29_10_07_28 - results_logger - INFO - Number of samples before balancing: class-0.0=620669 class-1.0=125784 class-2.0=20964 class-4.0=20964
2023_10_29_10_07_28 - results_logger - INFO - timer for resample_data (RandomUnderSampler) started
2023_10_29_10_07_28 - results_logger - INFO - Time elapsed since the begining of resample_data (RandomUnderSampler): 0.161468000 s
2023_10_29_10_07_28 - results_logger - INFO - Number of samples after balancing: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_10_07_28 - results_logger - INFO - timer for random forest :  started
2023_10_29_10_07_29 - results_logger - INFO - timer for evaluate_model_score started
2023_10_29_10_07_29 - results_logger - INFO - Sample of predicted labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.] 
 versus actual labels: 0     0.0
1     0.0
2     0.0
3     0.0
4     0.0
5     0.0
6     0.0
7     0.0
8     0.0
9     0.0
10    1.0
11    0.0
12    0.0
13    1.0
14    0.0
15    0.0
16    0.0
17    0.0
18    1.0
19    0.0
Name: label, dtype: float64
2023_10_29_10_07_29 - results_logger - INFO - Number of predicted 1 labels: 46876.0 
 versus number of predicted 0 labels: 93202.0
2023_10_29_10_07_29 - results_logger - INFO - Accuracy: 98.40%
2023_10_29_10_07_29 - results_logger - INFO - {
    "0.0": {
        "precision": 0.9991307725028203,
        "recall": 0.9804896640592389,
        "f1-score": 0.9897224512228635,
        "support": 110198.0
    },
    "1.0": {
        "precision": 0.9121229461293223,
        "recall": 0.9958054439982151,
        "f1-score": 0.9521290212475467,
        "support": 22410.0
    },
    "2.0": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 3735.0
    },
    "4.0": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 3735.0
    },
    "accuracy": 0.9839803538028813,
    "macro avg": {
        "precision": 0.9778134296580356,
        "recall": 0.9940737770143635,
        "f1-score": 0.9854628681176025,
        "support": 140078.0
    },
    "weighted avg": {
        "precision": 0.9852574143764466,
        "recall": 0.9839803538028813,
        "f1-score": 0.9842562432788491,
        "support": 140078.0
    }
}
2023_10_29_10_07_29 - results_logger - INFO - Confusion Matrix: 
2023_10_29_10_07_29 - results_logger - INFO - True Positives: 22316
2023_10_29_10_07_29 - results_logger - INFO - True Negatives: 108048
2023_10_29_10_07_29 - results_logger - INFO - False Positives: 2150
2023_10_29_10_07_29 - results_logger - INFO - False Negatives: 94
2023_10_29_10_07_29 - results_logger - INFO - AUC: 0.93
2023_10_29_10_07_29 - results_logger - INFO - Time elapsed since the begining of evaluate_model_score: 0.653571000 s
2023_10_29_10_07_29 - results_logger - INFO - Time elapsed since the begining of random forest : : 1.381033000 s
2023_10_29_10_07_29 - results_logger - INFO - timer for clustering started
2023_10_29_10_07_29 - results_logger - INFO - timer for scaling_duration started
2023_10_29_10_07_29 - results_logger - INFO - Time elapsed since the begining of scaling_duration: 0.000706000 s
2023_10_29_10_07_29 - results_logger - INFO - Number of samples before rebalancing and limiting rows: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_10_07_29 - results_logger - INFO - Number of samples after rebalancing and limiting rows: class-0.0=1875 class-1.0=1875 class-2.0=1875 class-4.0=1875
2023_10_29_10_07_29 - results_logger - INFO - min_samples: 937
2023_10_29_10_07_29 - results_logger - INFO - timer for clustering_duration_for_0.01 started
2023_10_29_10_18_44 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.01: 674.165730000 s
2023_10_29_10_18_44 - results_logger - INFO - eps: 0.01, number of clusters: 3, silhouette score: 0.5749053359031677, noise points: 1369
2023_10_29_10_18_44 - results_logger - INFO - timer for clustering_duration_for_0.02 started
2023_10_29_10_29_49 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.02: 664.292675000 s
2023_10_29_10_29_49 - results_logger - INFO - eps: 0.02, number of clusters: 3, silhouette score: 0.5749053359031677, noise points: 1369
2023_10_29_10_29_49 - results_logger - INFO - timer for clustering_duration_for_0.03 started
2023_10_29_10_41_29 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.03: 699.778419000 s
2023_10_29_10_41_30 - results_logger - INFO - eps: 0.03, number of clusters: 3, silhouette score: 0.574790894985199, noise points: 1371
2023_10_29_10_41_30 - results_logger - INFO - timer for clustering_duration_for_0.04 started
2023_10_29_10_54_20 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.04: 770.278420000 s
2023_10_29_10_54_21 - results_logger - INFO - eps: 0.04, number of clusters: 3, silhouette score: 0.574790894985199, noise points: 1371
2023_10_29_10_54_21 - results_logger - INFO - timer for clustering_duration_for_0.05 started
2023_10_29_11_07_17 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.05: 776.637103000 s
2023_10_29_11_07_18 - results_logger - INFO - eps: 0.05, number of clusters: 3, silhouette score: 0.574790894985199, noise points: 1371
2023_10_29_11_07_18 - results_logger - INFO - Best eps: 0.01, number of clusters: 3, silhouette score: 0.5749053359031677, noise points: 1369
2023_10_29_11_07_18 - results_logger - INFO - Associating clusters to labels : 
 {-1.0: {0.0: 31, 1.0: 40, 2.0: 56, 4.0: 33}, 0.0: {0.0: 35, 1.0: 40, 2.0: 26, 4.0: 32}, 1.0: {0.0: 77, 1.0: 91, 2.0: 76, 4.0: 96}, 2.0: {0.0: 32, 1.0: 45, 2.0: 45, 4.0: 42}}
2023_10_29_11_07_18 - results_logger - INFO - Time elapsed since the begining of clustering: 3588.869441000 s
2023_10_29_11_07_18 - results_logger - INFO - End time : 1698577638.697475
2023_10_29_11_07_18 - results_logger - INFO - Total duration: 3591.085700273514
2023_10_29_11_07_18 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim16_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_29_11_07_18 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=1, word_character_size=16, embedding_dim=16, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_29_11_07_38 - results_logger - INFO - token number for instance 1 (with padding) : 2049
2023_10_29_11_07_38 - results_logger - INFO - encoder summary : Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense_6 (Dense)             (None, None, 16)          32        
                                                                 
 model_3 (Functional)        (None, 2049, 16)          430       
                                                                 
 model_4 (Functional)        (None, 2049, 16)          430       
                                                                 
 global_average_pooling1d_1  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_11 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 1164 (4.55 KB)
Trainable params: 1164 (4.55 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_11_07_38 - results_logger - INFO - timer for transformers training :  started
2023_10_29_12_27_29 - results_logger - INFO - Time elapsed since the begining of transformers training : : 4790.740848000 s
2023_10_29_12_27_29 - results_logger - INFO - TransformersHyperParams : {'index': 1, 'word_character_size': 16, 'embedding_dim': 16, 'transformer_units': 2, 'num_heads': 2, 'num_transformer_layers': 2, 'dropout_rate': 0.1, 'activation': 'relu'}
2023_10_29_12_27_29 - results_logger - INFO - ///---!!!! Launching testing pipeline on dataset /root/phdtrack/mem2graph/data/26_filtered_chunk_extraction_-e_only-max-entropy_-s_none !!!!----///
2023_10_29_12_27_29 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_29_12_27_29 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_29_12_27_29 - results_logger - INFO - Start time : 1698582449.472572
2023_10_29_12_27_29 - results_logger - INFO - Using already loaded data
2023_10_29_12_27_29 - results_logger - INFO - timer for feature_engineering started
2023_10_29_12_27_29 - results_logger - INFO - Computing correlation (algorithm: pearson)...
2023_10_29_12_27_31 - results_logger - INFO - Correlation matrix (algorithm: pearson): 
             embedded_0  embedded_1  ...  embedded_14  embedded_15
embedded_0     1.000000   -0.705513  ...          NaN     0.999905
embedded_1    -0.705513    1.000000  ...          NaN    -0.705456
embedded_2          NaN         NaN  ...          NaN          NaN
embedded_3    -0.943959    0.898746  ...          NaN    -0.943915
embedded_4     0.967737   -0.848356  ...          NaN     0.967606
embedded_5    -0.198247    0.739666  ...          NaN    -0.198231
embedded_6    -0.522897    0.948268  ...          NaN    -0.522850
embedded_7     0.999995   -0.705511  ...          NaN     0.999943
embedded_8          NaN         NaN  ...          NaN          NaN
embedded_9     0.999988   -0.705508  ...          NaN     0.999960
embedded_10   -0.916367    0.912897  ...          NaN    -0.916255
embedded_11   -0.867815    0.963655  ...          NaN    -0.867746
embedded_12   -0.779121    0.981073  ...          NaN    -0.779058
embedded_13    0.999514   -0.705146  ...          NaN     0.998988
embedded_14         NaN         NaN  ...          NaN          NaN
embedded_15    0.999905   -0.705456  ...          NaN     1.000000

[16 rows x 16 columns]
2023_10_29_12_27_31 - results_logger - INFO - Correlation matrix saved at: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_12_27_30_991129.png and /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/feature_correlation_matrices/correlation_matrix_pearson_2023_10_29_12_27_30_991074.csv
2023_10_29_12_27_31 - results_logger - INFO - Correlation sums: 
embedded_0     10.901057
embedded_1     10.819793
embedded_2      0.000000
embedded_3     11.763542
embedded_4     11.657091
embedded_5      6.273246
embedded_6      9.523379
embedded_7     10.900971
embedded_8      0.000000
embedded_9     10.900889
embedded_10    11.767376
embedded_11    11.675884
embedded_12    11.307687
embedded_13    10.896002
embedded_14     0.000000
embedded_15    10.899913
dtype: float64
2023_10_29_12_27_31 - results_logger - INFO - Sorted correlation sums: 
embedded_10    11.767376
embedded_3     11.763542
embedded_11    11.675884
embedded_4     11.657091
embedded_12    11.307687
embedded_0     10.901057
embedded_7     10.900971
embedded_9     10.900889
embedded_15    10.899913
embedded_13    10.896002
embedded_1     10.819793
embedded_6      9.523379
embedded_5      6.273246
embedded_2      0.000000
embedded_8      0.000000
embedded_14     0.000000
dtype: float64
2023_10_29_12_27_31 - results_logger - INFO - Keeping columns: ['embedded_2', 'embedded_8', 'embedded_14', 'embedded_5', 'embedded_6', 'embedded_1', 'embedded_13', 'embedded_15']
2023_10_29_12_27_31 - results_logger - INFO - End feature engineering
2023_10_29_12_27_31 - results_logger - INFO - Time elapsed since the begining of feature_engineering: 1.877904000 s
2023_10_29_12_27_31 - results_logger - INFO - Keeping 8 : ['embedded_2', 'embedded_8', 'embedded_14', 'embedded_5', 'embedded_6', 'embedded_1', 'embedded_13', 'embedded_15']
2023_10_29_12_27_31 - results_logger - INFO - Keeping 8 : ['embedded_2', 'embedded_8', 'embedded_14', 'embedded_5', 'embedded_6', 'embedded_1', 'embedded_13', 'embedded_15']
2023_10_29_12_27_31 - results_logger - INFO - Number of samples before balancing: class-0.0=620669 class-1.0=125784 class-2.0=20964 class-4.0=20964
2023_10_29_12_27_31 - results_logger - INFO - timer for resample_data (RandomUnderSampler) started
2023_10_29_12_27_31 - results_logger - INFO - Time elapsed since the begining of resample_data (RandomUnderSampler): 0.148764000 s
2023_10_29_12_27_31 - results_logger - INFO - Number of samples after balancing: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_12_27_31 - results_logger - INFO - timer for random forest :  started
2023_10_29_12_27_32 - results_logger - INFO - timer for evaluate_model_score started
2023_10_29_12_27_32 - results_logger - INFO - Sample of predicted labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.] 
 versus actual labels: 0     0.0
1     0.0
2     0.0
3     0.0
4     0.0
5     0.0
6     0.0
7     0.0
8     0.0
9     0.0
10    1.0
11    0.0
12    0.0
13    1.0
14    0.0
15    0.0
16    0.0
17    0.0
18    1.0
19    0.0
Name: label, dtype: float64
2023_10_29_12_27_32 - results_logger - INFO - Number of predicted 1 labels: 46782.0 
 versus number of predicted 0 labels: 93296.0
2023_10_29_12_27_32 - results_logger - INFO - Accuracy: 98.44%
2023_10_29_12_27_32 - results_logger - INFO - {
    "0.0": {
        "precision": 0.9989467459994826,
        "recall": 0.9811611825985953,
        "f1-score": 0.9899740882829596,
        "support": 110198.0
    },
    "1.0": {
        "precision": 0.9148202855736091,
        "recall": 0.9949129852744311,
        "f1-score": 0.953187123252533,
        "support": 22410.0
    },
    "2.0": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 3735.0
    },
    "4.0": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 3735.0
    },
    "accuracy": 0.9843658533102986,
    "macro avg": {
        "precision": 0.9784417578932729,
        "recall": 0.9940185419682566,
        "f1-score": 0.9857903028838731,
        "support": 140078.0
    },
    "weighted avg": {
        "precision": 0.985544169072628,
        "recall": 0.9843658533102986,
        "f1-score": 0.9846234812939566,
        "support": 140078.0
    }
}
2023_10_29_12_27_32 - results_logger - INFO - Confusion Matrix: 
2023_10_29_12_27_32 - results_logger - INFO - True Positives: 22296
2023_10_29_12_27_32 - results_logger - INFO - True Negatives: 108122
2023_10_29_12_27_32 - results_logger - INFO - False Positives: 2076
2023_10_29_12_27_32 - results_logger - INFO - False Negatives: 114
2023_10_29_12_27_32 - results_logger - INFO - AUC: 0.93
2023_10_29_12_27_32 - results_logger - INFO - Time elapsed since the begining of evaluate_model_score: 0.644376000 s
2023_10_29_12_27_32 - results_logger - INFO - Time elapsed since the begining of random forest : : 1.309276000 s
2023_10_29_12_27_32 - results_logger - INFO - timer for clustering started
2023_10_29_12_27_32 - results_logger - INFO - timer for scaling_duration started
2023_10_29_12_27_32 - results_logger - INFO - Time elapsed since the begining of scaling_duration: 0.000674000 s
2023_10_29_12_27_32 - results_logger - INFO - Number of samples before rebalancing and limiting rows: class-0.0=20964 class-1.0=20964 class-2.0=20964 class-4.0=20964
2023_10_29_12_27_32 - results_logger - INFO - Number of samples after rebalancing and limiting rows: class-0.0=1875 class-1.0=1875 class-2.0=1875 class-4.0=1875
2023_10_29_12_27_32 - results_logger - INFO - min_samples: 937
2023_10_29_12_27_32 - results_logger - INFO - timer for clustering_duration_for_0.01 started
2023_10_29_12_40_13 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.01: 760.134469000 s
2023_10_29_12_40_13 - results_logger - INFO - eps: 0.01, number of clusters: 3, silhouette score: 0.7379494309425354, noise points: 1299
2023_10_29_12_40_13 - results_logger - INFO - timer for clustering_duration_for_0.02 started
2023_10_29_12_52_25 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.02: 731.259721000 s
2023_10_29_12_52_25 - results_logger - INFO - eps: 0.02, number of clusters: 3, silhouette score: 0.7379494309425354, noise points: 1299
2023_10_29_12_52_25 - results_logger - INFO - timer for clustering_duration_for_0.03 started
2023_10_29_13_04_44 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.03: 738.923279000 s
2023_10_29_13_04_45 - results_logger - INFO - eps: 0.03, number of clusters: 3, silhouette score: 0.7379494309425354, noise points: 1299
2023_10_29_13_04_45 - results_logger - INFO - timer for clustering_duration_for_0.04 started
2023_10_29_13_17_27 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.04: 761.430407000 s
2023_10_29_13_17_27 - results_logger - INFO - eps: 0.04, number of clusters: 3, silhouette score: 0.7379494309425354, noise points: 1299
2023_10_29_13_17_27 - results_logger - INFO - timer for clustering_duration_for_0.05 started
2023_10_29_13_29_51 - results_logger - INFO - Time elapsed since the begining of clustering_duration_for_0.05: 743.313265000 s
2023_10_29_13_29_52 - results_logger - INFO - eps: 0.05, number of clusters: 3, silhouette score: 0.3740614056587219, noise points: 2696
2023_10_29_13_29_52 - results_logger - INFO - Best eps: 0.01, number of clusters: 3, silhouette score: 0.7379494309425354, noise points: 1299
2023_10_29_13_29_52 - results_logger - INFO - Associating clusters to labels : 
 {-1.0: {0.0: 29, 1.0: 37, 2.0: 56, 4.0: 32}, 0.0: {0.0: 37, 1.0: 43, 2.0: 26, 4.0: 33}, 1.0: {0.0: 77, 1.0: 91, 2.0: 76, 4.0: 96}, 2.0: {0.0: 32, 1.0: 45, 2.0: 45, 4.0: 42}}
2023_10_29_13_29_52 - results_logger - INFO - Time elapsed since the begining of clustering: 3739.406415000 s
2023_10_29_13_29_52 - results_logger - INFO - End time : 1698586192.2533853
2023_10_29_13_29_52 - results_logger - INFO - Total duration: 3742.780813217163
2023_10_29_13_29_52 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_29_13_29_52 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=2, word_character_size=8, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_29_13_30_26 - results_logger - INFO - token number for instance 2 (with padding) : 4098
2023_10_29_13_30_26 - results_logger - INFO - encoder summary : Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense_12 (Dense)            (None, None, 8)           16        
                                                                 
 model_6 (Functional)        (None, 4098, 8)           222       
                                                                 
 model_7 (Functional)        (None, 4098, 8)           222       
                                                                 
 global_average_pooling1d_2  (None, 8)                 0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_17 (Dense)            (None, 8)                 72        
                                                                 
=================================================================
Total params: 532 (2.08 KB)
Trainable params: 532 (2.08 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_13_30_26 - results_logger - INFO - timer for transformers training :  started
2023_10_29_15_03_47 - results_logger - ERROR - Timeout error in transformers pipeline 2, skipping (and marking)
2023_10_29_15_03_47 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim16_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_29_15_03_47 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=3, word_character_size=8, embedding_dim=16, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_29_15_04_24 - results_logger - INFO - token number for instance 3 (with padding) : 4098
2023_10_29_15_04_24 - results_logger - INFO - encoder summary : Model: "model_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_18 (Dense)            (None, None, 16)          32        
                                                                 
 model_9 (Functional)        (None, 4098, 16)          430       
                                                                 
 model_10 (Functional)       (None, 4098, 16)          430       
                                                                 
 global_average_pooling1d_3  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_23 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 1164 (4.55 KB)
Trainable params: 1164 (4.55 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_15_04_24 - results_logger - INFO - timer for transformers training :  started
2023_10_29_16_37_44 - results_logger - ERROR - Timeout error in transformers pipeline 3, skipping (and marking)
2023_10_29_16_37_45 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim8_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_29_16_37_45 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=4, word_character_size=16, embedding_dim=8, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_29_16_38_06 - results_logger - INFO - token number for instance 4 (with padding) : 2049
2023_10_29_16_38_06 - results_logger - INFO - encoder summary : Model: "model_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_24 (Dense)            (None, None, 8)           16        
                                                                 
 model_12 (Functional)       (None, 2049, 8)           676       
                                                                 
 model_13 (Functional)       (None, 2049, 8)           676       
                                                                 
 model_14 (Functional)       (None, 2049, 8)           676       
                                                                 
 model_15 (Functional)       (None, 2049, 8)           676       
                                                                 
 global_average_pooling1d_4  (None, 8)                 0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_33 (Dense)            (None, 8)                 72        
                                                                 
=================================================================
Total params: 2792 (10.91 KB)
Trainable params: 2792 (10.91 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_16_38_06 - results_logger - INFO - timer for transformers training :  started
2023_10_29_18_11_27 - results_logger - ERROR - Timeout error in transformers pipeline 4, skipping (and marking)
2023_10_29_18_11_27 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim16_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_29_18_11_27 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=5, word_character_size=16, embedding_dim=16, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_29_18_11_45 - results_logger - INFO - token number for instance 5 (with padding) : 2049
2023_10_29_18_11_46 - results_logger - INFO - encoder summary : Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_18 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_34 (Dense)            (None, None, 16)          32        
                                                                 
 model_17 (Functional)       (None, 2049, 16)          1300      
                                                                 
 model_18 (Functional)       (None, 2049, 16)          1300      
                                                                 
 model_19 (Functional)       (None, 2049, 16)          1300      
                                                                 
 model_20 (Functional)       (None, 2049, 16)          1300      
                                                                 
 global_average_pooling1d_5  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_43 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 5504 (21.50 KB)
Trainable params: 5504 (21.50 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_18_11_46 - results_logger - INFO - timer for transformers training :  started
2023_10_29_19_45_07 - results_logger - ERROR - Timeout error in transformers pipeline 5, skipping (and marking)
2023_10_29_19_45_07 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim8_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_29_19_45_07 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=6, word_character_size=8, embedding_dim=8, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_29_19_45_46 - results_logger - INFO - token number for instance 6 (with padding) : 4098
2023_10_29_19_45_47 - results_logger - INFO - encoder summary : Model: "model_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_23 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_44 (Dense)            (None, None, 8)           16        
                                                                 
 model_22 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_23 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_24 (Functional)       (None, 4098, 8)           676       
                                                                 
 model_25 (Functional)       (None, 4098, 8)           676       
                                                                 
 global_average_pooling1d_6  (None, 8)                 0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_53 (Dense)            (None, 8)                 72        
                                                                 
=================================================================
Total params: 2792 (10.91 KB)
Trainable params: 2792 (10.91 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_19_45_47 - results_logger - INFO - timer for transformers training :  started
2023_10_29_21_19_09 - results_logger - ERROR - Timeout error in transformers pipeline 6, skipping (and marking)
2023_10_29_21_19_09 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim16_transformer_units4_num_heads4_num_transformer_layers4_dropout_rate03_activationrelu !!!!!!!!!!!!!
2023_10_29_21_19_09 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=7, word_character_size=8, embedding_dim=16, transformer_units=4, num_heads=4, num_transformer_layers=4, dropout_rate=0.3, activation='relu')
2023_10_29_21_19_43 - results_logger - INFO - token number for instance 7 (with padding) : 4098
2023_10_29_21_19_44 - results_logger - INFO - encoder summary : Model: "model_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       [(None, None, 1)]         0         
                                                                 
 dense_54 (Dense)            (None, None, 16)          32        
                                                                 
 model_27 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_28 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_29 (Functional)       (None, 4098, 16)          1300      
                                                                 
 model_30 (Functional)       (None, 4098, 16)          1300      
                                                                 
 global_average_pooling1d_7  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_63 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 5504 (21.50 KB)
Trainable params: 5504 (21.50 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_29_21_19_44 - results_logger - INFO - timer for transformers training :  started
2023_10_29_22_53_04 - results_logger - ERROR - Timeout error in transformers pipeline 7, skipping (and marking)
2023_10_30_07_39_00 - results_logger - INFO - Pipeline end time : 1698651540.043717 seconds
2023_10_30_07_39_00 - results_logger - INFO - Pipeline duration : 82600.62515544891 seconds
