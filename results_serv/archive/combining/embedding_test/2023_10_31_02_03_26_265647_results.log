2023_10_31_02_03_26 - results_logger - INFO - Passed program params:
2023_10_31_02_03_26 - results_logger - INFO - param[0]: main.py
2023_10_31_02_03_26 - results_logger - INFO - param[1]: -d
2023_10_31_02_03_26 - results_logger - INFO - param[2]: /root/phdtrack/mem2graph/data/25_filtered_chunk_extraction_-e_none_-s_activate
2023_10_31_02_03_26 - results_logger - INFO - param[3]: -p
2023_10_31_02_03_26 - results_logger - INFO - param[4]: deeplearning
2023_10_31_02_03_26 - results_logger - INFO - param[5]: -o
2023_10_31_02_03_26 - results_logger - INFO - param[6]: /root/phdtrack/phdtrack_openssh_memory_embedding/results_serv/output/25_filtered_chunk_extraction_-e_none_-s_activate
2023_10_31_02_03_26 - results_logger - INFO - param[7]: -otr
2023_10_31_02_03_26 - results_logger - INFO - param[8]: training
2023_10_31_02_03_26 - results_logger - INFO - param[9]: -ots
2023_10_31_02_03_26 - results_logger - INFO - param[10]: validation
2023_10_31_02_03_26 - results_logger - INFO - ///---!!!! Launching embedding pipeline on dataset /root/phdtrack/mem2graph/data/25_filtered_chunk_extraction_-e_none_-s_activate !!!!----///
2023_10_31_02_03_26 - results_logger - INFO - Data origins training : {<DataOriginEnum.Training: 'training'>}
2023_10_31_02_03_26 - results_logger - INFO - Data origins testing : {<DataOriginEnum.Validation: 'validation'>}
2023_10_31_02_03_26 - results_logger - INFO - Pipeline start time : 1698717806.2789865 seconds
2023_10_31_02_03_26 - results_logger - INFO - timer for load_samples_and_labels_from_all_csv_files started
2023_10_31_02_03_26 - results_logger - INFO - Loading samples and labels from 20964 files
2023_10_31_02_12_23 - results_logger - INFO - Number of loaded files: 20964
2023_10_31_02_12_23 - results_logger - INFO - Number of empty files: 0
2023_10_31_02_12_25 - results_logger - INFO - Loading samples and labels from 3735 files
2023_10_31_02_13_58 - results_logger - INFO - Number of loaded files: 3735
2023_10_31_02_13_58 - results_logger - INFO - Number of empty files: 0
2023_10_31_02_13_58 - results_logger - INFO - Time elapsed since the begining of load_samples_and_labels_from_all_csv_files: 632.324298000 s
2023_10_31_02_14_01 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_31_02_14_01 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=0, word_character_size=16, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_31_02_16_36 - results_logger - INFO - token number for instance 0 (with padding) : 271
2023_10_31_02_16_37 - results_logger - INFO - encoder summary : Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense (Dense)               (None, None, 8)           16        
                                                                 
 model (Functional)          (None, 271, 8)            222       
                                                                 
 model_1 (Functional)        (None, 271, 8)            222       
                                                                 
 global_average_pooling1d (  (None, 8)                 0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_5 (Dense)             (None, 8)                 72        
                                                                 
=================================================================
Total params: 532 (2.08 KB)
Trainable params: 532 (2.08 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_31_02_16_37 - results_logger - INFO - timer for transformers training :  started
2023_10_31_03_49_57 - results_logger - ERROR - Timeout error in transformers pipeline 0, skipping (and marking)
2023_10_31_03_49_57 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size16_embedding_dim16_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_31_03_49_57 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=1, word_character_size=16, embedding_dim=16, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
2023_10_31_03_53_34 - results_logger - INFO - token number for instance 1 (with padding) : 271
2023_10_31_03_53_35 - results_logger - INFO - encoder summary : Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, None, 1)]         0         
                                                                 
 dense_6 (Dense)             (None, None, 16)          32        
                                                                 
 model_3 (Functional)        (None, 271, 16)           430       
                                                                 
 model_4 (Functional)        (None, 271, 16)           430       
                                                                 
 global_average_pooling1d_1  (None, 16)                0         
  (GlobalAveragePooling1D)                                       
                                                                 
 dense_11 (Dense)            (None, 16)                272       
                                                                 
=================================================================
Total params: 1164 (4.55 KB)
Trainable params: 1164 (4.55 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

2023_10_31_03_53_35 - results_logger - INFO - timer for transformers training :  started
2023_10_31_05_26_55 - results_logger - ERROR - Timeout error in transformers pipeline 1, skipping (and marking)
2023_10_31_05_26_55 - results_logger - INFO - !!!!!!!!!!!!! Transformers instance : transformers_word_character_size8_embedding_dim8_transformer_units2_num_heads2_num_transformer_layers2_dropout_rate01_activationrelu !!!!!!!!!!!!!
2023_10_31_05_26_55 - results_logger - INFO - Transformers instance : TransformersHyperParams(index=2, word_character_size=8, embedding_dim=8, transformer_units=2, num_heads=2, num_transformer_layers=2, dropout_rate=0.1, activation='relu')
